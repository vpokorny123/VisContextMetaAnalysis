source("~/Library/CloudStorage/GoogleDrive-pokor076@umn.edu/My Drive/Pokorny Specials Meta-analysis/R scripts/Step4b_compute_effect_sizes_scz.R", echo=TRUE)
View(aux_info)
#read in acuity and stimuli location info from Table 1.
#THIS MEANS THAT IF YOU MAKE CHANGES TO TABLE 1 YOU NEED TO PROPAGATE THOSE CHANGES
#TO THIS TABLE
aux_info<-fread(paste0(dir2save,'/Table 1_revised.csv'))
colnames(aux_info)<-as.character(aux_info[2,])
aux_info <- aux_info[,c('Authors (Year)','Minimum Acuity Threshold',
'Target Stimulus Location (Foveal or Peripheral)')]
View(aux_info)
a
#read in acuity and stimuli location info
aux_info<-fread(paste0(dir2save,'/Table 2.csv'))
colnames(aux_info)<-as.character(aux_info[2,])
aux_info <- aux_info[,c(2,7,8,11)]
View(aux_info)
aux_info[,c('Authors (Year)','Minimum Acuity Threshold',
'Target Stimulus Location (Foveal or Peripheral)',
"Effect Size (Hedges' G)")]
source("~/Library/CloudStorage/GoogleDrive-pokor076@umn.edu/My Drive/Pokorny Specials Meta-analysis/R scripts/Step4b_compute_effect_sizes_scz.R", echo=TRUE)
source("~/Library/CloudStorage/GoogleDrive-pokor076@umn.edu/My Drive/Pokorny Specials Meta-analysis/R scripts/Step4b_compute_effect_sizes_scz.R", echo=TRUE)
source("~/Library/CloudStorage/GoogleDrive-pokor076@umn.edu/My Drive/Pokorny Specials Meta-analysis/R scripts/Step5_meta_analysis_fornel_plots.R", echo=TRUE)
j = "Contrast"
domain_df <- df[grepl(j,df$Domain),]
View(domain_df)
source("~/Library/CloudStorage/GoogleDrive-pokor076@umn.edu/My Drive/Pokorny Specials Meta-analysis/R scripts/Step4b_compute_effect_sizes_scz.R", echo=TRUE)
source("~/Library/CloudStorage/GoogleDrive-pokor076@umn.edu/My Drive/Pokorny Specials Meta-analysis/R scripts/Step5_meta_analysis_fornel_plots.R", echo=TRUE)
?regtest
reg_res$est
reg_res
reg_res$est
source("~/Library/CloudStorage/GoogleDrive-pokor076@umn.edu/My Drive/Pokorny Specials Meta-analysis/R scripts/Step5_meta_analysis_fornel_plots.R", echo=TRUE)
reg_res$est
View(reg_res)
reg_res
library(esc)
?esc_t
esc_t(t = 2.89, p = .034)
library(esc)
esc_t(t = 2.89, p = .034, totaln = 6)
library(esc)
esc_t(t = 2.89, p = .034, totaln = 6, es.type = "g")
library(pwr)
install.packages('pwr')
library(pwr)
?pwr.t.test
pwr.t.test(d = 1.887, sig.level = .05, power = .8)
pwr.t.test(d = 1, sig.level = .05, power = .8)
pwr.t.test(d = 1.5, sig.level = .05, power = .8)
pwr.t.test(d = 1.8, sig.level = .05, power = .8)
library(pwr)
pwr.t.test(d = 1.8, sig.level = .05, power = .8, type = "paired")
ovid_output_name <- "OVID_output_revision_keywords" # should be either OVID_output
ovid_output_name <- "OVID_output_revision_keywords" # should be either OVID_output
# or OVID_output_revision_keywords
data <- read_bibliography(paste0(ovid_output_name,'.ris'))
library(revtools)
library(revtools)
ovid_output_name <- "OVID_output_revision_keywords" # should be either OVID_output
# or OVID_output_revision_keywords
data <- read_bibliography(paste0(ovid_output_name,'.ris'))
initial_n <- nrow(data)
initial_n
#count number of articles from each source (MEDLINE, EMBASE and Psychinfo)
#OVID changed some of the way that metadata is handled so we will use different
#methods for the original vs. revision search
#we'll start with original search
if (ovid_output_name == 'OVID_output' ){
#EMBASE = 'emed'
#psychinfo = 'psyc'
#medline is everything else
medline<-sum(!is.na(data$DB))
medline
psyc<-sum(grepl('psyc',data$l2))
psyc
embase<-nrow(data)-(medline + psyc)
embase}
if (ovid_output_name == 'OVID_output_revision_keywords'){
medline<- sum(grepl('MEDLINE',data$DB))
psyc <- sum(grepl('APA',data$DB))
embase <- sum(grepl('Embase',data$DB))
print(paste0(medline,' articles from medline'))
print(paste0(psyc,' articles from psychinfo'))
print(paste0(embase,' articles from embase'))
#just checking to see if they add up to initial_n
medline + psyc + embase == initial_n
}
#15 seems like a good threshold
matches <- find_duplicates(data,
match_variable ="title",
method = "lv",
match_function = "stringdist",
threshold = 15)
#15 seems like a good threshold
matches <- find_duplicates(data,
match_variable ="title",
method = "lv",
match_function = "stringdist",
threshold = 15)
data_nodup <- extract_unique_references(data, matches)
dups_count <- initial_n - nrow(data_nodup)
#now get rid of poster abstracts
data_nodup_noconf<-data_nodup[!grepl('uppl', data_nodup$issue,ignore.case = TRUE) &
!grepl('conference|congress',
data_nodup$journal_secondary,ignore.case = TRUE),]
poster_count <- nrow(data_nodup) - nrow(data_nodup_noconf)
if (ovid_output_name == 'OVID_output_revision_keywords'){
data_nodup_noconf_norev <- data_nodup_noconf[data_nodup_noconf$PT!="Review",]
} else if (ovid_output_name == 'OVID_output'){
data_nodup_noconf_norev<-data_nodup_noconf[!grepl('review',data_nodup_noconf$PT,
ignore.case = TRUE),]
}
reviews_count <- nrow(data_nodup_noconf) - nrow(data_nodup_noconf_norev)
final_data<-data_nodup_noconf_norev[!grepl('dissertation',
data_nodup_noconf_norev$journal,
ignore.case = TRUE),]
dissertations_count <-nrow(data_nodup_noconf_norev) - nrow(final_data)
print(paste0(dups_count,' duplicates detected and removed'))
print(paste0(poster_count,' posters detected and removed'))
print(paste0(poster_count,' posters detected and removed'))
print(paste0(reviews_count,' reviews detected and removed'))
#maybe we want to look at dissertations later, but let's not worry about it for now
print(paste0(dissertations_count,' dissertations detected and removed'))
final_n = nrow(final_data)
final_n
print(paste0(final_n,' left after automatic cleaning'))
# now let's see how much overlap there is between the original and revised search
original_papers <- read_bibliography(paste0('OVID_output_cleaned.ris'))
# now let's see how much overlap there is between the original and revised search
original_papers <- read_bibliography(paste0('OVID_output_cleaned.ris'))
revision_papers <- read_bibliography(paste0('OVID_output_revision_keywords_cleaned.ris'))
# now let's see how much overlap there is between the original and revised search
original_papers <- read_bibliography(paste0('OVID_output_cleaned.ris'))
revision_papers <- read_bibliography(paste0('OVID_output_revision_keywords_cleaned.ris'))
new_papers <- setdiff(revision_papers$title, original_papers$title)
nrow(revision_papers)-nrow(new_papers)
nrow(revision_papers)
nrow(new_papers)
new_papers
nrow(revision_papers)-length(new_papers)
n_overlapping<-nrow(revision_papers)-length(new_papers)
print(paste0(n_overlapping,' overlapping articles between the two searches'))
new_papers_to_review <- revision_papers[match(new_papers, revision_papers$title),]
length(new_papers)
illusions
source("~/Library/CloudStorage/GoogleDrive-pokor076@umn.edu/My Drive/Pokorny Specials Meta-analysis/R scripts/Step5_meta_analysis_fornel_plots.R", echo=TRUE)
source("~/Library/CloudStorage/GoogleDrive-pokor076@umn.edu/My Drive/Pokorny Specials Meta-analysis/R scripts/Step5_meta_analysis_fornel_plots.R", echo=TRUE)
source("~/Library/CloudStorage/GoogleDrive-pokor076@umn.edu/My Drive/Pokorny Specials Meta-analysis/R scripts/Step5_meta_analysis_fornel_plots.R", echo=TRUE)
source("~/Library/CloudStorage/GoogleDrive-pokor076@umn.edu/My Drive/Pokorny Specials Meta-analysis/R scripts/Step5_meta_analysis_fornel_plots.R", echo=TRUE)
medline
psyc
embase
dups_count
dissertations_count
reviews_count
poster_count
n_overlapping
new_papers_to_review
